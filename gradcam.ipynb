{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "NUM_CLASSES = 9\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATH_TO_TEST_DATASET = \"data/CRC-VAL-HE-7K/\"\n",
    "\n",
    "from model import DeepCMorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded, unexpected keys: []\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "device = get_device()\n",
    "\n",
    "model = DeepCMorph(num_classes=NUM_CLASSES, freeze_classification_module=False)\n",
    "model.load_weights(dataset=\"CRC\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "test_dataset = datasets.ImageFolder(PATH_TO_TEST_DATASET, transform=test_transforms)\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=False, drop_last=False)\n",
    "TEST_SIZE = len(test_dataloader.dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue_labels = {\n",
    "    0: 'adipose',\n",
    "    1: 'background',\n",
    "    2: 'debris',\n",
    "    3: 'lymphocyte',\n",
    "    4: 'mucus',\n",
    "    5: 'smooth muscle',\n",
    "    6: 'normal colon mucosa',\n",
    "    7: 'cancer-associated stroma',\n",
    "    8: 'colorectal adenocarcinoma epithelium' # tumor\n",
    "}\n",
    "\n",
    "cell_labels = {\n",
    "    0: 'background',\n",
    "    1: 'epithelial cell', \n",
    "    2: 'connective tissue cell', \n",
    "    3: 'lymphocyte', \n",
    "    4: 'plasma cell', \n",
    "    5: 'neutrophil',  \n",
    "    6: 'eosinophil'\n",
    "}\n",
    "\n",
    "cell_colors = [\n",
    "    'black',      # background\n",
    "    'blue',       # epithelial cell\n",
    "    'green',      # connective tissue cell\n",
    "    'red',        # lymphocyte\n",
    "    'yellow',     # plasma cell\n",
    "    'purple',     # neutrophil\n",
    "    'orange'      # eosinophil\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1338, 2: 2185, 3: 2524, 4: 3158, 5: 4193, 6: 4785, 7: 5526, 8: 5947}\n"
     ]
    }
   ],
   "source": [
    "#find class offsets in the dataset\n",
    "class_offsets = {}\n",
    "for i in range(NUM_CLASSES):\n",
    "    class_offsets[i] = test_dataset.targets.index(i)\n",
    "    \n",
    "print(class_offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import cv2\n",
    "\n",
    "target_layers = [list(model.encoder.features.children())[-1]]\n",
    "  \n",
    "# pick image from each class\n",
    "images = [test_dataset[class_offsets[i]] for i in range(NUM_CLASSES)]\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images.\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "  for sample in images:\n",
    "    img = sample[0]\n",
    "    target = sample[1]\n",
    "    input_tensor = img.unsqueeze(0).to(device)\n",
    "    targets = [ClassifierOutputTarget(target)]\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    # In this example grayscale_cam has only one image in the batch:\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    image = np.float32(img.permute(1, 2, 0))\n",
    "    visualization = show_cam_on_image(image, grayscale_cam, use_rgb=False)\n",
    "    cv2.imwrite(f'cam_{tissue_labels[target]}.jpg', visualization)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rc_venv",
   "language": "python",
   "name": "rc_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
